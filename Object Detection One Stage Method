연구실에 들어와서 교수님이 처음으로 주신 세미나 그 전까지는 딥러닝쪽에 공부를 겉햝기 식으로만 해서 
사실상 아무것도 모른다고 봐야 했었는데 갑자기 세미나를 던져주고 가셔서 한 포스트를 집중적으로 리뷰를 해야했다.

Object Detection이란 여러 물체를 인식할 때 어떤 물체인지, 어디에 위치해 있는지를 알아내는 작업

Classification -> Label이 붙어있는 Output값으로 각각의 데이터를 분류하기 위해서 Classification으로 분류하는 과정 
간단하게 생각해서 그냥 분류하는 과정으로 이해하기로 했다.

Regional Proposal -> 이미지 전체를 훑어보는 식의 Sliding Window를 개선한 방식으로 이름 그대로 물체가 
있을듯한 '공간'을 '제안'하는 방식 다시말해 객체가 있을듯한 공간을 찾아내는 알고리즘이다.

위에 두 개를 왜 설명했냐면 One Stage 방식과 Two Stage 방식의 차이점이 두 개를 순차적으로 진행하느냐
동시에 진행하느냐의 차이이다. 
One Stage는 두 개를 동시에 진행해서 속도는 Two Stage에 비교해서 빠르지만 정확성이 조금 떨어진다
그 반대로 Two Stage는 두 개를 순차적으로 진행해서 속도는 느리지만 정확하다.

One Stage
미리 정의된 객체 클래스 집합을 인식하고 Bounding Box를 이용해서 각 객체의 위치 설명
다양한 백본 네트워크를 이용해서 풍부한 특징 표현 가능

일반적으로 이미지를 더 효과적으로 학습하기 위해서 Pre-Trained된 데이터를 가져와 전이학습합니다.

S*S 그리드 셀에 객체가 포함된 그리드 셀의 중앙을 Responsible이라고 표현한다.

바운딩박스 출력을 위해서 Tx, Ty, Th, Tw,C1,C2,C3,C4,Pobj 생성(5+C)
하지만 이렇게 하면 여러 객체를 표현할 수 없다.
그래서 같은 grid cell에 여러 객체가 속할 때는 B(5+C) 필터를 생성하여 시각화해서 N*N*B 예측을 생성한다.

Non-Maximum Suppression
중복되는 Bounding box를 조사해서 제일 높은 Confidence Score를 제외한 다른 박스는 모두 삭제한다.

Anchor Box -> 특정 너비과 폭이 사전 정의된 경계박스의 집합이며 앵커 박스를 사용할 때 모든 객체 예측을 한 번에 평가할 수 있습니다. 
앵커박스를 사용하는 물체 감지기는 전체 영상을 한 번에 처리할 수 있어 실시간 물체 감지 시스템이 가능하다.

IoU(Intersection over Union) -> 객체 인식 모델의 성능 평가를 하는 과정에서 사용되는 도구 
1. ground-truth bounding boxes(testing set에서 object 위치를 labeling 한것)
2. prediceted bounding boxes (model이 출력한 object 위치 예측값)
위의 두개의 bounding box의 교집합/합집합이 IoU이다.
최고 점수의 IoU를 가진 경계박스를 1로 정의하고 나머지는 다 0으로 기술한다.

나머지는 나중에... 아직 제대로 이해 못해서 조금 힘들다
 

